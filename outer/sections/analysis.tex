To analyze the resulting paper from the experiment, we will present the role and
contributions of the LLM in each phase of the paper writing process. There is no
clean accounting of which words or ideas were produced by the LLM and which were
produced by the human author, as the two were in constant dialogue in both
developing the argumentation and writing the text. However, we will present a 
qualitative analysis of the contributions of the LLM in each phase, and show
illustrative examples of the LLM's contributions and activities in each phase.
The full logs of all interactions with Llama are available in the appendix.

Note that in general it is not so obvious how one should evaluate the success of
co-authorship, even with a human coauthor. The goal of the project was to
produce an original and high-quality contribution to a field, but even if the 
LLM had not been able to produce any original ideas or argumentation, a
high-quality paper could still have been produced through the effort of the 
human authors alone, meaning that a high quality paper does not necessarily
indicate that the LLM performed well in the collaboration. Instead, the analysis
of each task will be guided by a few  specific questions that may be of interest
to the reader:
\begin{enumerate}
    \item What positive contributions did Llama make to the task?
    \item What were the limitations of Llama in this task?
    \item How did Llama's contributions compare to those that a human coauthor
          could have made?
    \item What, if anything, did Llama contribute that appears to be original
          or novel ideation?
    \item What was the experience of using Llama as a coauthor in this task
          like compared to working with a human?
    \item If given the chance to redo this phase of the project, would you
          choose to work with Llama again?
\end{enumerate}

\subsection{Literature Review}

The first phase of the project was to carry out a literature review,
interrogating the vague notion of the intersection between algorithmic fairness
measures and distributive justice. Working through this process requires
identifying gaps and frontiers in the literature in this area. A coauthor in
this phase of research might suggest relevant papers to read, or suggest a
particular angle to investigate based on their own expertise.

Completing this phase of the process with the LLM is critical for the
experiment, as including the relevant source and background materials into the
context memory mechanism is a necessary step to ensure that the LLM is on topic
and able to pull text from the relevant literature throughout the remainder of
the process. In a human collaboration, this step would be similarly critical in
a more reciprocal way. Both human authors need to have a pool of shared
knowledge from the literature to draw from and stimulate discussion. The
question then becomes whether the process with the LLM will be similarly
two-sided; will Llama be able to pull useful papers and ideas from the
literature to suggest to the human author? Or will this phase become independent
literature review on the part of the human author, compounded with having to
teach Llama the relevant background knowledge?

As an entry point to this phase, we often asked Llama to suggest papers to read
about a particular topic or concept, and to summarize those papers. For example,
``I'm interested in learning about entitlement theories of justice, particularly
their benefits and how they apply in the modern world. What papers can I read?''
Llama would reply with a list of papers and brief summaries of each, some of
which existed, and some of which did not as you would expect from an LLM. But 
the goal is not simply to cite existing papers, but for those papers to be
relevant and helpful in understanding the topic at hand. Llama has two very bad
habits in this regard. The first is to cite the foundational papers in the field
that the human author is clearly already familiar with, and the second is to 
suggest readings that are only vaguely related to the subject of the question.
So for example, Llama suggested I read ``Anarchy, State, and Utopia'' by Robert
Nozick which we had already discussed extensively earlier in the same
conversation, and that I read Locke's ``Second treatise of Government,'' which 
does discuss protections of individual property rights, but provides no positive
account of distributive justice. However Llama was also able to suggest some
papers which were relevant and interesting, such as ``Self-Ownership and
Property Rights'' by Eric Mack, which is a more recent positive account of
entitlement justice than Nozick's. 

Recommending real and relevant papers is not the only way to draw on the LLM in
the lit review phase. Most papers `hallucinated' by Llama have hallucinated 
titles, but not authors or publication years. Many of the papers suggested by
Llama that were not real are variations on real papers or are given titles
reflecting thoughts of the author that may be found in other papers. For example,
Llama suggested reading ``Entitlement Justice: A Review of the Literature'' by 
David Miller. This paper does not exist, but on further inspection, David Miller
wrote both a Stanford Encyclopedia of Philosophy entry on Justice that provides
an overview of the literature on Entitlement Justice, and a book called
``Principles of Social Justice'' which offers a critical perspective on Nozick's
theory.

Thus in literature review, Llama is helpful in finding new and relevant research
to read — but critically, less helpful than a human coauthor would be. When a
human coauthor suggests a list of papers, there is no need to check which ones
are real or not, and a lesser need to interrogate the relevance of the papers.
These are extra tasks that must be completed by the human author that do not
enhance the process of writing the paper. In this way, Llama is a less effective
coauthor than a human, but ``better than nothing.''

Llama is more helpful throughout literature review when it is asked to summarize
the arguments of a paper or to compare and contrast two papers. For example,
``Provide a summary of the paper `Counterfactual Fairness' for me. Compare the
measure proposed with equalized odds fairness.'' This question results in an
accurate and nuanced description of the paper, and comparison of the weaknesses
and strengths of equalized odds and counterfactual fairness. While this is a 
task that could be completed by a human coauthor, it is not a task that any 
coauthor would be willing to complete frequently or on demand. The tradeoff is 
somewhat obvious and expected—Llama \emph{can} give you reading suggestions,
summarize arguments and compare papers on demand and in real time, but with 
a significant effort on the part of the human author to extract the results.

\subsection{Research Question Development}

Beyond searching and summarizing the literature, Llama did have something to
offer in terms of new and interesting areas to explore through our research
question. When prompted to connect the Rawls/Nozick divide to the literature on
algorithmic fairness with no context beyond short descriptions of the two 
theories, Llama suggested the following:

``In the context of algorithmic fairness measures, Rawls' theory can be seen as
advocating for a more egalitarian approach, where algorithms are designed to
minimize biases and ensure equal opportunities for all individuals. This might
involve techniques such as data preprocessing, feature engineering, and
regularization to reduce the impact of biased data.

Nozick's theory, by contrast, might be seen as more permissive, allowing for the
existence of unequal outcomes as long as they are the result of just means. This
could lead to a focus on individualized fairness measures, where algorithms are
designed to optimize outcomes for specific individuals or groups, rather than
striving for overall fairness.

In practice, algorithmic fairness measures often aim to strike a balance between
these two perspectives. For example, algorithms might be designed to minimize
bias while still allowing for individualized treatment based on relevant
characteristics. This can involve techniques such as fairness-aware
optimization, debiasing, and explainability.''

This response is, admittedly, a bit vague and high level, but note that it
suggests an interesting avenue to explore that we cannot find any reference to
in the literature. The idea that the dichotomy between Nozick and Rawls should
be compared with and contrasted with the typical dichotomy between individual
and group fairness measures from algorithmic fairness is an interesting one, and
turned out to be a fruitful line of inquiry for the paper \emph{that we would
not have otherwise explored}. On follow-up questions, Llama expanded this area
of inquiry to point towards the literature on counterfactual fairness and how it
relates to individualized fairness, and suggested several relevant papers and
authors to read on this topic. This is a complex and nuanced approach to the
literature that Llama recommended, and one that we haven't found explicitly
examined elsewhere, nor one which we would've thought to explore so quickly
without Llama's prompting. Clearly, this is not a case in which Llama was used
as a tool to extract, refine, or sharpen our own ideas, but rather a
contribution of new external ideas into the research question development phase.

The manner in which Llama recommended this line of inquiry was less explicit and
direct than a human coauthor would be, and the ideas included were not as sharp
or sophisticated. However, there is a level of freedom in the engagement about 
these ideas that is not present in a human coauthor. When a human contributor
suggests an area of inquiry, it is accompanied with some impetus to pursue that
line of inquiry and to include it in the paper. This has both its advantages and
drawbacks. On the one hand, it is a good way to ensure that the paper is
robust and well-rounded, and that the authors are not simply pursuing their
own interests. On the other hand, it can lead to a longer research program in
total and reduce the coherence of the argumentation. Llama has no such
expectations, and can be prompted for ideas to explore as frequently as desired.
This is a double-edged sword, as it can lead to the discovery of productive
ideas that the author is interested in exploring, but can also generate wild
goose chases that are ultimately unproductive.

\subsection{Argumentation}

In argumentation, our hope for a coauthor was that it would be able to elucidate
and defend relevant, novel claims that represented a contribution to the area
of inquiry. This is the task in which Llama was the least helpful, and takes 
a major backseat to the human author.

Llama is able to produce text that is on topic, and which is structured in a way
that sounds like proper academic argumentation. However, the text produced lacks
specificity and nuance, and Llama often fails to truly defend its claims in 
proper detail—none of which should be surprising at this point in time. The
question at this phase of development of LLMs is not what limitations they have
in producing arguments, which is well known, but rather what meaningful 
contributions can be extracted from the outputs they produce in jointly
developing the argumentation.

Llama contributed to the argumentation in two main ways. The first was to
produce text which laid arguments out in a clear and concise manner when
prompted with the bulk of the argument. These presentations were often beyond
the claim inputted, but not so far beyond as to be considered a novel claim in
themselves. For example, when asked to present the claim that ``Group fairness
measures are irrelevant to entitlement theories of justice,'' Llama produced an
argument which started from elements of Nozick's theory and built up the claim
logically to the conclusion, including the consideration of counterarguments and 
objections that it had not been prompted to consider. The details of the
argument produced were not always accurate, and rarely complete, but the
structure served as a sort of template for the human author to fill in with
their own arguments. In this way, Llama goes beyond the standard capabilities of
human contributors, who would be very unlikely to help the author structure this
argument with this level of detail. However, the ultimate result is that the
critical thinking to really sharpen the argument originates from within the
human author, and Llama is not able to \emph{source} the argumentation in a way
that a coauthor would.

The second (and more useful) way Llama contributed to argumentation task was by
critiquing arguments presented to it. When asked to find gaps in an argument or
present objections to a claim being made, Llama was able to reliably locate 
weaknesses in the argumentation. While almost never capable of filling in the
identified gaps, Llama was able to identify them and articulate why they were
problematic or weak, in a way that was much more sophisticated than any of its
contributions to the argumentation itself (perhaps philosophy content on the 
internet favors critique over positing new ideas?).

\subsection{Writing}
Given a motivating research question, a number of relevant sources to call on,
and an argument to make, one might hope that the LLM would be able to produce
a rough draft of the full text of the paper that could be edited and refined by
the human author. This is far from the case.

Given an argument to make, Llama is able to produce text to defend it. Given 
sources to call on, Llama is able to produce text that develops some background
knowledge and context for the paper. Given a motivating research question, Llama
can provide a first pass at an introduction and conclusion section that connect
the two. However, Llama is not able to tie these ingredients together to produce
a coherent and well-structured paper. This is not surprising, as the buffer size
of the Llama-2-7b-32K model used is 32,768 token, or around 25,000 words. Given
that the length of the paper produced is around 8,000 words, and that the
context window consisted of a wealth of discussion, questioning, and sections 
from other sources, Llama was not able to have the full wealth of information
needed to produce the fully fleshed out paper. Of course, more sophisticated 
models with larger buffer sizes may outperform Llama in this regard. The text
produced by Llama is not only in need of line-editing, but instead often gives
the impression that Llama is not able to grasp the full arc of the argument
being made, and certainly not able to understand it within its full context.
It is clear, therefore, that the process of developing the writing must be more
iterative, with the human author closely monitoring the output and repeatedly
editing the text output by the LLM, as well as filling in the gaps in the
produced text. 

This process proceeds how one would expect — pass a section of text back and
forth between the human author and Llama, with each critiquing and editing
different aspects of the text until it is in a form acceptable to both authors.
This is a process which is time consuming, and ultimately it is unclear whether
the LLM is responsible for any of the writing, or only for the stylistic choices
and tone of the section. 

How does this compare to a human contributor? With a human, the process will 
most certainly be less iterative. The quality of the text initially produced by
the human coauthor will be higher quality in a positive collaboration, and the
author will then be expected to only make small changes to bring the text into
line with the general style, tone, and structure of the paper as a whole.
Working with the LLM brings the benefit of being able to delete, rephrase, and 
restructure as one wishes without worrying about the opinion of the coauthor,
but this advantage is certainly offset by the time and effort required to 
wrangle the LLM output into usable content for the paper.

\subsection{Revision}

The revision task of the paper is the most familiar and encouraged role for
LLMs in academic writing. It is common now to ask LLMs to proofread and edit
manuscripts for tone and style, and to suggest changes to the text to strengthen
the overall presentation of the argument. Besides the familiar and obvious
benefits of using Llama for these purposes, there were some less trivial gains
here that resulted from using Llama throughout the writing process. Since
the full process of writing the paper was held in Llama's context memory, it was
able to suggest changes and style considerations that were in the spirit of the
original intention of the paper rather than simply the text. For example, Llama 
suggested on one version of the paper that the introduction should be
restructured to include a more explicit statement of the research question.
Without doing the whole process in step with Llama, it would neither have known
what the research question was, nor whether it was clearly articulated in the
introduction.

A human coauthor would of course be able to make similar suggestions, but would
not be able to, for example, review ten versions of the paper in the span of a
week and suggest changes to each of them. However, if prompted with the research
question and an outline of the main argument presented in a paper, Llama likely
could have performed just as well as it did when involved with the full
end-to-end process. Therefore it isn't necessary to use Llama as a coauthor to 
gain the benefit of Llama as an editor, but Llama's editing capabilities are
one of the nicer features you get when using it as a coauthor, though are not 
responsible for producing novel or significant contributions in any way.
