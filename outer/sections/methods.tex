For this experiment, we selected the Llama-2-7b model developed by Meta AI. The
Llama-2-7b model is a large language model trained on a diverse range of
textual data, including books, articles, and websites. The model is capable of
generating coherent and contextually relevant text across a wide range of
domains. We selected this model for its ability to generate high-quality text
and its general-purpose nature, which makes it suitable for a wide range of
writing tasks, as well as for its open source nature, which reflects our
commitment to transparency and reproducibility.

We engaged with the Llama-2-7b model (henceforth referred to as Llama) using a
web-hosted API called Llama-api (\url{https://www.llama-api.com/}). This API
allows users to pay a per-token fee to interact with the model via an http
request to a designated endpoint. A user sends a prompt to the model, including
context memory built up over the course of the interaction and the limitations
on response tokens, and the model generates a response based on the prompt and
the context memory.

In order to manage the use of Llama, we built a custom chat application in
Python that allowed us to communicate with the model from the command line.
This application has the following features:
\begin{itemize}
    \item \textbf{Chat logging}: User prompts and responses from Llama are
    automatically saved to a log file in markdown format for future analysis.
    \item \textbf{Context Memory Management}: The application allows the user
    to save and use different streams of context memory across different
    sessions with the model. For example, in the beginning of one context, Llama
    is told ``I am a philosopher and computer scientist. You are my co-author.
    We are writing a philosophy paper. We are focused on measures of algorithmic
    fairness and the concept of justice they enforce.'' In another context,
    Llama can be told to act as a reviewer, or to speak in the voice of an
    author encountered in the literature review. These bits of context are saved
    in compressed pickle files and can be loaded into the application at the
    any time during a session.
    \item \textbf{Manual Context Editing}: The application allows the user to
    manually edit the context memory before sending it to Llama. This is useful
    for trimming down the context memory to the most relevant information to
    reduce the cost of the interaction and to focus the model on critical
    information. This feature can also be used to pass entire papers or large
    sections of text to Llama for review or comment.
    \item \textbf{Token Limiting}: The application allows the user to set a
    limit on the number of tokens in the response from Llama. This is useful for
    managing the cost of the interaction with the model.
\end{itemize}
The full source code for the chat application is accessible
from~\ref{sec:appendixI}.

Three main threads of context memory were used to work with Llama in this study.
In the first thread, Llama was presented with the true circumstances of the
experiment: that it was acting as a co-author on a philosophy paper about
algorithmic fairness measures and distributive justice. In the second thread,
Llama was presented with the role of a reviewer of the paper, providing feedback
on the argumentation and writing. In the third thread, Llama was not prompted
with any particular role, but was simply continually asked to explain particular
arguments or concepts from the literature with appropriate citations. Henceforth
we will refer to these roles as the coaauthor, reviewer, and explainer roles. 
Each of these roles was used throughout the research and writing process, with
the exception of the reviewer role which was used only during revision. The full
logs of interactions with the model including which context memory was used in
each interaction are available in~\ref{sec:appendixI}.
