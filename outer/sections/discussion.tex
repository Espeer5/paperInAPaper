The results of this experiment were generally mixed, with Llama performing well
in some respect and poorly in others. Of particular notice was that the model,
though not specifically prompted to do so, took on a few discrete roles over the
course of the project. Here, we will outline those high-level roles, and discuss
the overall benefits of using Llama as a collaborator in this manner.

One of the most interesting aspects of this research was the way that Llama took
on different and unintended discrete roles in different tasks throughout the writing
process. In the literature review, Llama successfully took on the role of a 
very educated assistant, providing citations and information from external
sources that were unknown to the human author. This can be understood as a
retrieval mode, where Llama retrieves information from its training data and
presents it in a coherent and relevant way. In the research question
formulation task, Llama took on the role of a genuine intellectual collaborator
in the sense of producing novel insights and ideas that were external to both
the human author and the training data. This can be understood as a generative
mode, where Llama generates new ideas and arguments that are not simply
retrieved from its training data. Then throughout argumentation, writing, and 
revision, Llama opted into a refinement mode, wherein it took information from
the human author and refined it into a more coherent and polished form.

While it was only during the research question formulation task that Llama
produced genuinely novel ideas, we should still consider this as a success in
eliciting original ideas from the model. The model was able to produce original
ideas and arguments that were not simply retrieved from its training data as far
as we can tell, and did not stem from the human author's own ideas, meaning that
the model was able to genuinely contribute to the research process. This is
significant in the face of the LLM usage policies of the journals described
previously; should the human author of this collaboration be considered the sole
author of the paper? How should the human author have credited Llama for its
ideas if not as a coauthor?

If a human coauthor engaged in this level of collaboration, it would be
expected that they would be included as a coauthor on the paper. The level of 
collaboration was much closer than commenting on one's manuscript or providing
a few references to the literature. Small sections of the paper are entirely
produced by Llama, and the majority of the paper is a product of a novel 
research direction that originated within Llama. Having demonstrated a current
LLM's ability to produce original ideas and arguments, we should consider 
whether it is ethical to exclude LLMs from authorship. Is some credit due to the
designers of the LLM? At the very least, the human author shouldn't be
over-credited for ideas that they did not produce. At the very least, if
LLMs are to be excluded from authorship, accompanying policies should limit the
human author's ability to interact with LLMs in generative ways which 
lead to the production of new ideas until such issues are resolved. This,
however, is far from an ideal solutionâ€”the ideas produced by LLMs have the
potential to advance human knowledge and understanding in a way that we 
shouldn't like to see stifled.

It is clear that Llama delivered some value to the project through the 
contribution of original ideas and arguments, but also clear from the analysis
that there are definite limitations to the model's capabilities. Were we to
attempt to complete a similar research program in the future, we would certainly
use Llama or a model with similar capabilities again, but only in particular
phases of the research process and in certain roles. For example, we would
certainly perform the literature review task with Llama again, and make full use
of its ability to retrieve relevant sources. We would also certainly use Llama
in the research question development task again, as it was able to produce novel
insights that proved useful. However, in the writing and revision phase, we
would use Llama as a critic, and not as a resource to produce the text of the
paper.

In trying to cooperate very closely on the writing of the text of the paper, we
felt that since Llama was not able to grasp the full arc of the argument of the
paper at any given time, it actually proved detrimental to the writing to have
Llama produce any of the text. Since Llama was not able to understand the full
context and structure, it tended to produce writing that reemphasized points
multiple times, or that was overly general. Pulling from the model's training
data, it was very good at producing descriptions of background concepts and 
arguments, but was not very good at demonstrating how those concepts and 
arguments were relevant to the specific research question at hand, nor at 
driving the argument forward. The result was a number of intermediate drafts
that required significant reframing and editing to be useful. Ultimately, we
were left with the impression that writing the full text of the paper alone
and using LLMs solely as a source of feedback and critique would have been a
more effective approach.

The implications of this experiment for the future of academic writing are
profound. LLMs will continue to improve at a rapid pace, and it is likely that 
their ability to produce original ideas and arguments will increase rapidly
along with them. Given that our current policies for LLM usage in academic
writing are already apparently outdated, it is clear that they need to be 
revised to reflect not only the current capabilities, but also the future
capabilities of LLMs. This will require a rethinking of the role of LLMs in
academic writing, and a consideration of the ethical implications of their use.
The legal and ethical implications of LLMs in academic writing are complex and
require exploration and discussion. 

It is clear that LLMs will play an important role in the future of academic 
writing, and it is essential that we begin to consider the implications of their
use. This paper is a first step in that direction, and we hope that it will
inspire further research and discussion on this important topic.
