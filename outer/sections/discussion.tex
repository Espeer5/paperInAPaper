One of the most interesting aspects of this research was the way that Llama took
on different and unintended modalities in different tasks throughout the writing
process. In the literature review, Llama successfully took on the role of a 
very educated assistant, providing citations and information from external
sources that were unknown to the human author. This can be understood as a
retrieval mode, where Llama retrieves information from its training data and
presents it in a coherent and relevant way. In the research question
formulation task, Llama took on the role of a genuine intellectual collaborator
in the sense of producing novel insights and ideas that were external to both
the human author and the training data. This can be understood as a generative
mode, where Llama generates new ideas and arguments that are not simply
retrieved from its training data. Then throughout argumentation, writing, and 
revision, Llama opted into a refinement mode, wherein it took information from
the human author and refined it into a more coherent and polished form.

While it was only during the research question formulation task that Llama
produced genuinely novel ideas, we should still consider this as a success in
eliciting original ideas from the model. The model was able to produce original
ideas and arguments that were not simply retrieved from its training data, and
did not stem from the human author's own ideas, meaning that the model was able
to genuinely contribute to the research process. This is significant in the face
of the LLM usage policies of the journals describe previously; perhaps the human
author could be held accountable for \emph{publishing} ideas produced by Llama, 
but should those ideas really be contributed to the human author if they are
genuinely originated within the model?

If a human coauthor engaged in this level of collaboration, it would be
expected that they would be included as a coauthor on the paper. The level of 
collaboration was much closer than commenting on one's manuscript or providing
a few references to the literature. Small sections of the paper are entirely
produced by Llama, and the majority of the paper is a product of a novel 
research direction that originated within Llama. Having demonstrated a current
LLM's ability to produce original ideas and arguments, we should consider 
whether it is ethical to exclude LLMs from authorship. At the very least, if
LLMs are to be excluded from authorship, accompanying policies should limit the
human author's ability to interact with LLMs in generative modalities which 
lead to the production of new ideas until such issues are resolved.

The implications of this experiment for the future of academic writing are
profound. LLMs will continue to improve at a rapid pace, and it is likely that 
their ability to produce original ideas and arguments will increase rapidly
along with them. Given that our current policies for LLM usage in academic
writing are already apparently outdated, it is clear that they need to be 
revised to reflect not only the current capabilities, but also the future
capabilities of LLMs. This will require a rethinking of the role of LLMs in
academic writing, and a consideration of the ethical implications of their use.
The legal and ethical implications of LLMs in academic writing are complex and
require exploration and discussion. 

It is clear that LLMs will play an important role in the future of academic 
writing, and it is essential that we begin to consider the implications of their
use. This paper is a first step in that direction, and we hope that it will
inspire further research and discussion on this important topic.
