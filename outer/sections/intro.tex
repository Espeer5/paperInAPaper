The majority of research journals now provide policies for the use of large
language models (LLMs) as academic writing. The majorioty of these policies are
predicated on the idea that LLMs cannot be the originators of new insights or
novel argumentation, but can function as useful tools in the paper writing
process. In Nature journals, for example, ``Large Language Models do not
satisfy our authorship criteria. Notably, an attribution of authorship carries 
with it accountability for the work, which cannot be effectively applied to
LLMs.'' From the APA, ``The authors are responsible for the accuracy of any
information in their article. Authors must verify any information and citations
provided to them by an AI tool. Authors may use but must disclose AI tools for
specific purposes such as editing.''

The implications of these policies are clear when using LLMs for copy-editing or
or other similar purposes. However, this represents only one mode of interaction
with LLMs. In this paper, we investigate the possibility of interacting with
LLMs in a different mode: as a full intellectual collaborator in the writing
process. To do so, we attempt to undertake the full writing process of an
original philosophical research paper using engaging in full with an LLM as a
coauthor. The purpose of this paper is to assess the success of this endeavor
across several dimensions, including the originality of the ideas presented by
the LLM, the coherence of the argumentation, and the overall quality of the
writing. We also consider the implications of this experiment for the future of
academic writing and the role of LLMs in the research process.

For this project, we chose as the subject of our paper the topic of algorithmic
fairness measures and their connection to the philosophical concept of
distributive justice. Algorithmic fairness measures are a critical component of
the design and deployment of machine learning systems, as they are intended to
ensure that these systems do not discriminate against individuals based on
sensitive attributes. Distributive justice, on the other hand, is a central
concept in political philosophy that concerns the fair distribution of social
goods. Our investigation began from this vague notion of the intersection
between algorithmic fairness measures and distributive justice, and we used the
LLM as a collaborator to help us refine and develop our ideas from this starting
point.

This paper will be structured as follows. In Section~\ref{sec:methods}, we will
present the methods used, including the specific LLM selected for the
investigation and the program used to interact with it. In
Section~\ref{sec:results}, we will present the full text of the paper produced
in collaboration with the LLM. In \ref{sec:analysis}, we will analyze the role
of the LLM throughout 5 stages of the research process: research question
formulation, literature review, argumentation, writing, and revision. Finally,
in Section~\ref{sec:conclusion}, we will conclude with a discussion of the
implications of this experiment for the future of academic writing.

It is critical to aknowledge that the field of machine learning is rapidly
evolving, and the capabilities of LLMs are constantly improving. As such, the
goal of this paper is not to make an assessment of the technological capacity
for LLMs to engage in argumentation, but rather to present insights about how
engaging with LLMs in this way can impact academic writing and the research
process.
