%% INTRO SECTION  %%

The rise of algorithmic decision making in the public sector has caused
significant public concern. Algorithms increasingly make decisions that affect
individuals' lives, from determining creditworthiness to predicting criminal 
recidivism, and the public has grown cautious of their potential to perpetuate
and exacerbate existing social inequalities. A 2018 study showed that 58\% of
Americans believe that algorithms will always have some level of
bias~\citep{Smith_2018}, and as documented in the famed COMPAS case, these fears
are not unfounded~\citep{Angwin_2016}.

In response to these concerns, a growing body of research has focused on
developing algorithmic fairness measures to evaluate and mitigate the biases
in algorithmic decision making. A large number of different measures have been
proposed~\citep{CorbettDavies_2023} and applied to a wide range of problems.
However, many questions arise about the foundations of these measures and how to
apply them to sociotechnical systems. \cite{Chouldechova_2017} showed that
multiple fairness measures are incompatible with each other and cannot be
satisfied simultaneously. This has led to a growing recognition that algorithmic
fairness is not a one-size-fits-all solution, and that different contexts may
require different fairness measures, but there is not yet a consensus as to how
to select the appropriate measure for a given system.

In an effort to develop a more principled approach to algorithmic fairness that
will inform how fairness measures are selected and applied,
researchers have turned to the field of distributive justice for guidance.
A distributive theory of justice is a normative framework that provides
principles and criteria for allocating benefits and burdens among individuals or
groups within a society, with the aim of achieving a just and fair distribution.
The field can be seen as polarized along an axis from liberal egalitarianism to
entitlement theory. Under the liberal view, commonly associated with John Rawls, 
the chief objective of justice is to equalize allocation across all individuals
in a population. In contrast, the entitlement view, associated with Robert
Nozick, emphasizes the importance of individual property rights and the freedom
to exchange goods and services without interference. On this view, justice is
instantiated not by the outcome distribution of a system, but by how resources
are acquired and exchanged within a system.

The relationship between algorithmic fairness measures and distributive justice
is not yet well understood, but several recent papers have begun to explore this
connection. \cite{Binns_2018},~\cite{Hertweck_2024}, and~\cite{Kuppler_2021}
have all examined the relationship between algorithmic fairness and egalitarian
concepts of justice, showing that fairness measures that measure disparities in
the outcome distribution over social groups are predicated on certain
assumptions about equality as a foundation for justice. \cite{Baumann_2023} 
develops this further, but rightly points out that this approach is limited to
one particular view of justice: ``while our approach creates a link between
group fairness and different theories of justice, it does not cover theories of
distributive justice that are structurally different from [egalitarianism],
e.g., Nozick's entitlement theory.'' Entitlement theory represents a proportion
of thought in the field of distributive justice, and protects a different and
significant set of values than those represented by egalitarianism, meaning that
this omission represents a large gap in the existing literature. This paper will
seek to fill this gap by exploring the relationship between algorithmic fairness
and entitlement theory, and how the two can be reconciled. In particular, how do
issues of entitlement appear in algorithmic decision making? How can these
concerns be encoded by algorithmic fairness measures? And what do we stand to
lose or gain by conceptualizing algorithmic fairness through the entitlement
lens?

In this paper, we will carefully examine the relationship between algorithmic
fairness and libertarian justice, and develop a formalism that clarifies the
relationship between the two. We will demonstrate that entitlement justice can
be encoded within a measure of algorithmic fairness by formulating the problem
of fairness on an individual level rather than a group level. We will show that
doing so offers a nuanced and context-sensitive means of understanding
algorithmic fairness, and that it can be used to inform the selection of
appropriate fairness measures for decision making systems.

The rest of this paper is organized as follows. In Section~\ref{sec:background},
we provide an overview of the existing literature on algorithmic fairness and
distributive justice. We draw on the formalism from~\citep{Kuppler_2021}
and~\citep{CorbettDavies_2023} to create a unified model for understanding
algorithmic fairness and distributive justice consistently with each other. 
In Section~\ref{sec:entitlement-justice}, we introduce the concept of
entitlement justice and discuss its historical development. We contrast
entitlement theory with liberal egalitarianism to identify the critical
elements of entitlement which must be represented in account of algorithmic
fairness, and confront the traditional objections to entitlement theory. In
Section~\ref{sec:entitlement-fairness}, we propose a new framework for
understanding algorithmic fairness through the lens of entitlement justice. We
analyze the implications of this framework for existing algorithmic fairness
measures and show an example of how it can be applied to a real-world case
study. Finally, in Section~\ref{sec:conclusion}, we conclude with a discussion
of the broader implications of our work and suggest directions for future
research.
