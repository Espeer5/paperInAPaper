In order to understand the relationship between algorithmic fairness and
entitlement justice, it is important to first analyze the role of the
algorithmic decision-maker in the context of entitlement systems. On the 
entitlement approach, decisions about allocations are made entirely based on
property rights. Therefore the task of a decision-maker within our decision
problem is clear — the decision-maker becomes a \emph{property rights oracle}.
Given a resource and information about a population of individuals, the job of
the decision-maker is to determine which individuals hold property rights over
the resource. The role of fariness is thus a bit different than under other
theories of justice, because we do not start from the assumption of any sort of
equality across our population. What type of assumption should we start with 
instead? To understand this, we will analyze the points of contrast we have
drawn between the Rawlsian and entitlement theories of justice.

\subsection{Fairness in Process}

One critical dimension of entitlement justice is that it governs the process
that gives rise to a distribution of resources rather than the distribution
itself. This means that decisions about allocation which govern whether a
particular individual is able to acquire a given resource must be made in
accordance with a fair process. Rather than answering whether or not a given
decision-maker outputs a fair distribution, we must instead ask whether the
manner in which decisions about allocations are made is fair. This is a
subtle but important distinction. Under the entitlement approach, the output
distribution is allowed to be heavily skewed in favor of some individuals or
groups if it represents the true distribution of property rights, but the
process by which the output distribution is arrived at must be in accordance
with the principles of just acquisition.

As an example, consider the case of college admissions. Under the liberal
egalitarian approach, we mighty ask whether the output distribution of our
algorithm is fair by asking whether it results in a roughly equal number of
students admitted between race A and race B. Under the entitlement approach,
however, there is no reason to ask this question — we might find that the
students entitled to admissions are 90\% members of race B. Instead, the
relevant questions are how race is used in the admissions process  — are
students from race A subject to the same rules of acquisition? Drawing on the
framework of the Lockean proviso, given that two students, one from each race,
have expended equal effort in their applications and studies, are the values
endowed in their applications treated as equal? It is evident that to encode
entitlement fairness, we cannot simply measure the ouputs of an algorithm, but
rather must analyze the treatment of protected features of individuals within
the algorithm itself.

\subsection{Individual Responsibility}

Our second critical dimension of entitlement justice is that it places
emphasis on the actions and properties of individuals, while de-emphasizing
the role of group membership. Under the entitlement approach, individuals
perform actions that give rise to or forfeit their property rights. Fairness
must therefore be fundamentally based on a set of features of individuals which
are relevant to the process of determining property rights. These features will
generally not be simple demographic features or features encoded in the input
covariates in a straightforward way, but rather will be a set of more nuanced
features that must be predicted on the input data by a complicated
high-deminsional model. For example, in the case of college admissions you may
want to predict a feature like ``cultural fit'' which will be difficult to
extract. These features can be sorted into two broad categories:
\begin{itemize}
    \item \emph{Positive Entitlement Features}: These are features of an
    individual that give rise to property rights. For example, an
    individual's effort in an application process might be a positive
    entitlement feature that gives rise to their right to be admitted
    to a college.
    \item \emph{Negative Entitlement Features}: These are features of an
    individual that forfeit their property rights. For example, if
    an individual cheats on their application, or performs very poorly on an
    entrance exam, these might be negative entitlement features that
    forfeit their right to be admitted to a college. 
\end{itemize}
Notice that given the full set of relevant positive and negative features of an
individual that determine their property rights, we should be able to fully
determine the individual's entitlement to a resource and complete the decision
problem. In other words, once we have identified the features and computed
them on an individual, the output of the decision maker can be fully specified
by these features alone. This lends itself to a natural understanding of
fairness in process — the process of mapping an individual to their decision
should be fully decided through the morally relevant features identified. These
features should be explicitly justified and made transparent to the
individuals affected by the decision. 

Returning to our discussion of modern entitlement theories, we can recognize
that the identification of relevant features is how context-specificity will
enter into our account of algorithmic fairness. In each problem domain for 
algorithmic decision-making, there will be a different set of positive and
negative features that are relevant to the entitlement being decided. By
identifying and justifying the set of features relevant in each domain, we
allow our account of fairness to be sensitive to the context and nuances of the
problem at hand. This is a powerful contrast to typical approaches to fairness
under which we attempt to identify a universal measure of fairness that can be
applied across all domains.

In application, this implies a particular set of structural conditions that must
be followed to implement an algorithm which is fair under the entitlement
approach. A classification scheme must be developed that first computes the
value of each of the relevant positive and negative entitlement features for
each individual in the population. Then a decision must be reached through only
those computed features, in isolation from the full input data to the algorithm.
This may seem to stand in stark contrast to the way that many machine learning
algorithms are currently developed. For example, in a typical supervised
learning setting, a model is trained to map a set of inputs to a set of outputs
according to a high-dimensions loss funtion, with little regard for the
manner in which the inputs are processed. However, the internal structure of
neural networks and other machine learning models gives rise to a set of
features computed by the model, constituting a lower-dimensional representation
of the input data~\citep{Liu_2018}. The approach we suggest here can be thought
of as a way of manually specifying a lower dimensional set of features that
are morally relevant to implement individual fairness over as a way of
exercising control over how the model makes decisions in order to implement
fairness as a process.

What would selection of these features look like in practice? Consider again the case of
college admissions, and in particular, how decision are made about admissions of
students who have less access to resources and academic opportunities. There are
several features that are not straightforwardly encoded in the input data but
are certainly relevant to the entitlement
\begin{itemize}
    \item Firstly, we might want to extract a feature that captures the notion
    of current academic performance. This is likely a function of GPA, test
    scores, and other typical academic indicators, and is justified by an appeal
    to the idea that students who perform well academically are more likely to
    succeed in college. Likelihood of success is made relevant by the fact
    that individuals who are likely to succeed at the university return gains 
    to the university, and therefore justify their admissions in a free market
    of talent.
    \item In contrast, we should also say that a student is entitled to admissions if
    they have demonstrated a stronger work ethic and commitment level than their
    peers, even if they attended a lower income school and thereby has less 
    access to advanced classes and tutoring resources. Effort and commitment
    demonstrate a greater value endowed into an application, and therefore a
    higher degree of entitlement.
    \item Finally, we might also want to consider a studen't cultural fit and
    addition to the campus community. This feature reflects a student's
    entitlement on the basis of more than just academic merit — a student who
    provides cultural value to a university provides similar, though reduced
    value to the univerisity as a student who provides academic value, and
    therefore has a similar, though lesser, entitlement.
\end{itemize}
An algorithm meant to implement entitlement fairness in college admissions
would then consist of predictors which extract each of these values for each
individual, and then a system of mapping these values to a decision about
admissions. 

Now, one critical dimension of fairness remains to be discussed — how do we
ensure that the predictors which compute the value of the relevant features for
each individual are themselves fair? To understand this question, we should
delve into the basis of the entitlement features themselves. Positive features
of an individual give rise to property rights through the mixing of one's self 
with the subject of the entitlement itself. If one's college application
demonstrates a strong work ethic, the individual has spent significant effort to
endow their application with value derived from their own self-ownership. The
right to self-ownership is a fundamental principle that does represent one form
of equality baked into the entitlement approach — we are required to treat the 
endowment of value derived from self-ownership as equal across all individuals,
irrespective of their characteristics or group membership. Notice that I care 
about this on an individual basis — if for just one person I value their
self-ownership less than another, I have failed to respect their property 
rights. As a result, it seems clear that the appropriate way to ensure that 
predictors of positive entitlement features are fair is to ensure that they
satisfy counterfactual fairness. Holding fixed those covariatates of an
individual which give rise to the positive entitlement feature, we must ensure
that the predictor outputs the same value regardless of the individual's other
features.

For negative entitlement features, the situation is a bit different. Rather than
gaining an entitlement through the mixing of one's self with the subject of the
entitlement, the basis for negative entitlement features is the failure to
respect the inherent rights of others. For example, if an individual cheats on
entrance exam scores that they include in their application, they are attempting
a coercive act that violates the rights of other students who are applying
honestly and in doing so, they forfeit their ability to gain entitlement over
admissions. In this case, our chief fairness concern is with errors in the
predictor. Wrongful accusations of negative features result in the depriivation
of one's property rights and therefore must be avoided. Similarly, mistakenly
identifying an individual as not having a negative feature results in the 
unjust deprivation of someone else's property rights in the population. It is a
property of algorithmic predictors that false positives and false negatives will
occur, but critically, this risk should be distributed evenly across all persons,
otherwise we will violate justice in acquisition, which, in Nozick's formulation,
demands that all persons have opportunity to acquire holdings. As a result,
we must ensure that the predictors of negative entitlement features balance 
false positive and false negative rates across groups.

\subsection{Entitlement Fairness and Redistribution}

A third critical dimension of entitlement justice is that it rejects the notion
of redistribution. Under the entitlement approach, once property rights have
been established, they must be respected and protected, and no attempt should be
made to redistribute resources in order to achieve a more equal distribution.
Note that this is already successfully encoded in the system we have described.
Once the set of morally relevant features have been identified, the decision
problem output must be entirely separated from the input data given the relevant
features. This means that no redistributive scheme may be implemented after the
property rights decision that attempts to balance the distribution of resources
over less fortunate individuals.

We are, however, offered a mechanism through entitlement theory for improving
outcomes for those who have been wrongfully disadvantaged through the principle
of rectification. For example, if we find that a particular group of individuals
has been systematically excluded from a resource due to a historical injustice,
rectification allows us to then consider membership in that group to be a
positive entitlement feature, and to thereby account for it within the decision
problem. This is a powerful mechanism for addressing historical injustices
and allows us to consider the broader social context in which our algorithm is
situated. 

\subsection{Measuring Fairness}

Having developed a qualitative account of entitlement fairness, we may now
formalize our account in a way that allows us to measure it. We can
define a measure of entitlement fairness as follows. Given our typical decision
problem, identify a set of morally relevant features of each individual in the
population, $V = \{v_1, v_2, \ldots, v_j\}$. These features should be
partitioned into two sets, $V^+$ and $V^-$ where $V^+$ contains the positive
entitlement features and $V^-$ contains the negative entitlement features 
relevant to the problem domain. Implement a predictor for each feature,
$v_j = \hat{p_j}(X)$. Now, these are the conditions for entitlement fairness:
\begin{enumerate}
    \item $P[f(X_1) = 1 | V = v] = P[f(X_2) = 1 | V = v]\;\forall X_1, X_2$ (Independence Condition)
    \item $P[p_{j, A\leftarrow a}(X) = 1 | X=x, A=a] = P[p_{j, A\leftarrow b}(X) = 1 | X=x, A=a]\;\forall a, b \in A, v_j \in V^+$ (Positive Feature Counterfactual Condition)
    \item $P[p_j(X) = 1 | v_j(X) = 0, A = a] = P[p_j(X) = 1 | v_j(X) = 0, A = b]\;\forall a, b \in A, v_j \in V^-$ and 
    $P[p_j(X) = 0 | v_j(X) = 1, A = a] = P[p_j(X) = 0 | v_j(X) = 1, A = b]\;\forall a, b \in A, v_j \in V^-$ (Negative Feature Odds Condition)
\end{enumerate}

\todo{College admissions example all the way through}
