The entitlement fairness measure derived here is a novel approach to algorithmic
fairness and represents a first attempt to formalize an account of justice that
is consistent with a historical rather than end-state theory of justice. Here we
will briefly discuss the benefits and limitations of this approach, and suggest
some directions for future research.

\subsection{Benefits of the Entitlement Fairness Measure}

The entitlement fairness framework has several advantages over existing fairness
measures. Firstly, it is a measure which has baked in context sensitivity. In
selected a set of positive and negative features which are relevant to the
decision problem at hand, the fairness measure is able to capture concerns about
the decision problem that could not be captured by simple disparity measures
across groups. 

In each problem domain the framework is applied to, the system designer must
make conscious choices about the features that are allowed to be used in the 
decision process, and must defend those choices in light of the particulars of
the domain. The framework cannot be implemented in one context, and then naively
applied to a different context which it might not be appropriate for, since its
application requires careful consideration. This stands in contrast
to existing measures of algorithmic fairness, which can be applied to any system
without extensive consideration of the idiosyncrasies of the problem domain. For
example, consider the case of the COMPAS algorithm, in which the original
designers of the algorithm measured its fairness using predictive parity across
races, which is a measure of accuracy across groups. Predictive parity is
appropriate for some problem domains, particularly those where the base rates of
the predicted outcome are the same across groups. The COMPAS system was later
revealed to be discriminatory based on differing false positive rates across 
groups due to a large discrepancy in the base rate of recidivism between racial
groups. When using the entitlement fairness measure, there may be no simple lift
and shift of the measure from one system to another as there was for the
predictive parity metric into the COMPAS system, and as a result cases where an
unsuitable measure is applied to a system are less likely to occur.

Secondly, the entitlement fairness measure is one that is well-aware of its own
limitations and assumptions. Part of the requirement of entitlement fairness is
the baked-in necessity for a system of rectification for entitlement violations.
This holds the system implementer accountable for the decisions made by the
system and for providing remedies for those harmed by the system. A system
cannot be entitlement fair without a way to appeal and rectify the decision made
by the system, meaning that the system is always open to scrutiny and
correction. One key result is that one can't simply measure their system against
one definition of fairness, declare it to be fair, and then put the system into
production without oversight and recourse. This is a key difference from 
existing fairness measures in that it increases the accountability of the system
implementer to the system's users to maintain the system's fairness over time
and provide support for their users. 

The final benefit of the entitlement fairness measure is that it gives a high
level of transparency to the population it is employed on. Not only do
individuals who decisions are made on have recourse to appeal their decisions, 
but they have a clear understanding of the features that are being used to make
the decision and the justification for those features. This is a key 
result of the entitlement fairness measure, as it allows some small level of
explanation to be provided to the individuals who are affected by the system.
This is a key difference from existing fairness measures, which may help to
soothe concerns about how some particular variables are used in the decision 
process, but not actually provide or identify the features that are used in the
decision process. This transparency could be considered a sort of explanation
for the decision process as now legally required in some jurisdictions.

\subsection{Limitations of the Entitlement Fairness Measure}

The entitlement fairness measure is not without its limitations. The framework
is much more difficult to apply than existing fairness measures, as it requires
a great deal more effort up front to identify relevant features to the
problem domain and the arrangement of a system of rectification. This is a key
current limitation of the system, as it is unlikely that many organizations
will be willing to put the framework into practice due to the high cost of
implementation and the need for a high level of transparency. Keeping up a
system of rectification requires human effort and resources and is likely to
be a significant burden on the organization.

The entitlement fairness measure is also highly limited by the requirement of 
justification of the features used in the decision process. While 
an organization may provide justifications for the features they use in their
decision process, it is highly unlikely that the justifications will be
universally accepted or uncontroversial. The result is that by publishing the 
reasoning behind the features used to make the decision, the organization
is likely to open itself up to a great deal of scrutiny and criticism from the
public, and possibly gaming of the systemâ€”more than it would have received if
it had simply used a standard fairness and not published extensive
justifications. While this is an unfortunate consequence of the framework, it
is also a typical consequence of any change that promotes transparency and
accountability and is a necessary step in the development of a more principled
approach to algorithmic fairness.

\subsection{Future Directions}

While this work has made significant strides in understanding the relationship
between algorithmic fairness and entitlement justice, several important
questions remain unanswered. 

First, the framework presented here is limited to the case of binary
classification problems. While the framework can be extended to multi-class
classification problems, the extension is not straightforward and requires
significant additional work. The extension of the framework to multi-class
classification problems is a key area for future research, as many real-world
applications of algorithmic decision making are multi-class classification
problems.

Second, the framework presented here is limited to the case of discrete
features. The extension to continuously valued features opens new questions
around how to define the normative relevance of features and how to measure the 
success of a particular feature in the decision process. Similarly,
rectification becomes much more difficult in the case of continuously valued
features, as the system implementer must now decide what threshold values
represent a mistake by the algorithm that requires rectification.

Finally, though the framework presented here is a coherent way to understand
entitlement justice in the setting of algorithmic decision-making, a large
step in the development of the approach would be to develop a test system which
implements the framework and demonstrates its utility in a real-world setting.
Though many examples are provided in this paper to demonstrate the capabilities
of the framework, a real-world system would validate and strengthen the 
arguments made in this paper.
